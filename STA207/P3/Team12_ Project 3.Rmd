---
title: "STA 207 Project 3,"
output: 
  pdf_document: default
  html_document:
    df_print: paged
    fig_caption: yes
    number_sections: true
---

<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
math {
  font-size: tiny;
}  
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE)
```

Team ID: 12

Name (responsibilities): Joseph Gonzalez (Proofread, Introduction, Background)

Name (responsibilities): Yanhao Jin (Main analysis, Causal statement, Conclusion and discussion)

Name (responsibilities): Ruichen Xu (Descriptive analysis, Plots and tables, Data processing)

Name (responsibilities): Bohao Zou (Main analysis, Model diagnostics)

# 1. Introduction

This study's purpose is to estimate the effects of drunk driving deterrents and other possible related factors on the number of vehicle fatalities. In this project, we use an annual time-series data set that contains state cross-sections for the 48 contiguous states of the U.S. from 1982 to 1988. For the data set and experiment, (a)all fatality rates are based on the information contained in the National Highway Traffic Safety Administration's (NHTSA) Fatal Accident Reporting System (FARS). The FARS contains data on all motor vehicle accident fatalities, which is categorized by the state of occurrence. (b) This dataset also includes an extensive set of categorical variables that describe the various state laws related to driving or alcohol. These laws represent all important DUI legislation. The information, provided by the NHTSA's annual compilation, constructed all law variables. It is also important to note that the legislation for each state is independent of the others. (c) The relationship between all variables and youth border crossing can be roughly ignored due to unifonnicy of drinking ages and the fact that the grandfather clauses pertain to stare residents only. (d) During the 1980s, numerous states authorized police to administer roadside breath tests for alcohol, enacted administrative per se laws that require license suspension or revocation if a driver's blood alcohol content (BAC) exceeds a prespecified level and mandated minimum jail sentences or community service for driving under the influence (DUD, authorized lawsuits against alcohol servers (dram shop laws)). [1]

In particular, we are interested in the following issues:

* Find the important factors that can potentially affect the fatality rate in the state.
* Determine if a mandatory jail sentence is associated with reduced traffic fatalities.
* Based on the analysis, make suggestions for policymakers to reduce the fatality rate.                                           

# 2. Statistical Analysis

Disparities in difficult to observe characteristics such as road conditions, driving patterns, and social attitudes towards drinking may influence interstate differences in vehicle mortality. Studies that choose to ignore this heterogeneity may generate biased estimates, which are a result of the correlation between the unobserved factors and cross-state variations in alcohol policies. To balance this heterogeneity, it is appropriate to use the linear fixed-effect model. That is

$$\small Y_{it}=\mu+\boldsymbol{\beta}_{1}^{T}\mathbf{X}_{it}+\boldsymbol{\beta}_{2}^{T}\mathbf{Z}_{i}+\varepsilon_{it}$$
where $\small Y_{it}$ is the fatality rate for the $\small i$-th state and time $\small t$. $\small\boldsymbol{\beta}$ is the coefficient vector for the selected  explanatory variables in the model, $\small \mathbf{X}_{it}$ is the selected  explanatory variables for $\small i$-th state and year $\small t$. $\small \boldsymbol{\beta}_{i}$ is the coefficient vector for the time-invariant explanatory variables. $\mathbf{Z}_{i}$ is the time-invariant explanatory variables which measures the unobserved time-invariant heterogeneities across the state. $\small \varepsilon_{it}$ is the individual-specific random effect, which measures the deviation of the fatality rate for $\small t$-th year from the average fatality rate over all years the $\small i$-th state.

Here is the analysis plan for the project:

* Using descriptive analysis for the overview of the data set and get basic ideas about which factors are potentially important.
* Starting with fitting the full model with all variables in the data set, we use AIC criteria to select important variables. 
* Fit the optimal model and conduct model diagnostics.
* Test whether having a mandatory jail sentence is associated with reduced traffic fatalities.
* Check what conclusion we can draw from the proposed statistical model and what causal interpretation we can make based on the analysis.

Following assumptions are made in our model:

* The observations across each state are independent and identically distributed.
* $\small \varepsilon_{it}$ are normally distributed 

# 3. Results

```{r message=FALSE, echo=FALSE, include=FALSE}
library("AER")
data("Fatalities")

### calculate different fatal ratio
### fatal ratio day
Fatalities$FRD1517 = (Fatalities$fatal1517 - Fatalities$nfatal1517) / Fatalities$pop1517
### fatal ratio night
Fatalities$FRN1517 = Fatalities$nfatal1517 / Fatalities$pop1517
### 
Fatalities$FRD1820 = (Fatalities$fatal1820 - Fatalities$nfatal1820) / Fatalities$pop1820
###
Fatalities$FRN1820 = Fatalities$nfatal1820 / Fatalities$pop1820
###
Fatalities$FRD2124 = (Fatalities$fatal2124 - Fatalities$nfatal2124) / Fatalities$pop2124
###
Fatalities$FRN2124 = Fatalities$nfatal2124 / Fatalities$pop2124
### others situation
Fatalities$FRD_other = (Fatalities$fatal - Fatalities$nfatal - (Fatalities$fatal1517 - Fatalities$nfatal1517) - 
                          (Fatalities$fatal1820 - Fatalities$nfatal1820) - (Fatalities$fatal2124 - Fatalities$nfatal2124)) / (Fatalities$pop - Fatalities$pop1517
                                                                                                                              - Fatalities$pop1820 - Fatalities$pop2124)
Fatalities$FRN_other = (Fatalities$nfatal - Fatalities$nfatal1517 - Fatalities$nfatal1820 - Fatalities$nfatal2124) / (Fatalities$pop - Fatalities$pop1517
                                                                                                                        - Fatalities$pop1820 - Fatalities$pop2124)
factorDrinkAge = c()
drinkAge = Fatalities$drinkage
for (i in c(1:length(drinkAge))){
  if (18 <= drinkAge[i] && drinkAge[i] < 19){
    factorDrinkAge[i] = 1
  }
  else if (19 <= drinkAge[i] && drinkAge[i] < 20){
    factorDrinkAge[i] = 2
  }
  else if (20 <= drinkAge[i] && drinkAge[i] < 21){
    factorDrinkAge[i] = 3
  }
  else{
    factorDrinkAge[i] = 4
  }
}


changeableData = Fatalities
changeableData$drinkage = as.factor(factorDrinkAge)
for (i in c(1:14)){
  changeableData = changeableData[,-17]
}
### fatal involve alcohol
changeableData$FR_IA = Fatalities$afatal / Fatalities$pop
changeableData$FR_NOIA = (Fatalities$fatal - Fatalities$afatal) / Fatalities$pop
changeableData$FR = (Fatalities$fatal) / Fatalities$pop
### Normalization
normalization = function(x){
  return((x - mean(x)) / sd(x))
}
changeableData = changeableData[,-8]
normData = changeableData
### if the type of col is numeric, then do a normalization on it.
for (i in c(1:dim(changeableData)[2])){
  if (is.numeric(normData[,i])){
    normData[,i] = normalization(normData[,i])
  }
  else{
    normData[,i] = normData[,i]
  }
}


### analysis
library("plm")
### we only do additive model. why??
library("MASS")
normColNames = colnames(normData)
x_variables = normColNames[1:19]
y_variables = normColNames[20:dim(changeableData)[2]]


### remove NA value 
normData = normData[-28,]


FindFinalModelForY = function(Y_Name,x_variables_Names,usedData){
  len = length(x_variables_Names)
  formulaString = paste(Y_Name,"~",sep = "")
  upperString = "~"
  for (i in c(1:(len))){
    if (i == 1){
      formulaString = paste(formulaString,normColNames[i],sep = "")
      upperString = paste(upperString,normColNames[i],sep = "")
    }
    else{
      formulaString = paste(formulaString,normColNames[i],sep = "+")
      upperString = paste(upperString,normColNames[i],sep = "+")
    }
  }
  formulaString = paste(formulaString,"-1",sep = "")
  upperString = paste(upperString,"-1",sep = "")
  fullModel = lm(as.formula(formulaString),data = usedData)
  finalStep = stepAIC(fullModel,scope = list(upper = as.formula(upperString),lower = as.formula(~state + year - 1)), direction = "both",k = 2)
  return(finalStep)
}
### This is the model with Time-Fixed and State-Fixed interaction
selectedModel = FindFinalModelForY("FR",x_variables,normData)
summary(selectedModel)


### The coefficient of dry and miles are not significant, so, we drop those variables.
### because we need to judge if there is relationship with jail, so , we add jail variable to this model.

######### 
## At this step, we need to test weather it needs to contain time-fixed effect
########

#########
### Final model  FR ~ spirits + unemp + income + beertax + jail
#########

state_time_fixed_lm = lm(FR ~  -1 + state + year + spirits + unemp + income + beertax + jail,data = normData)
anova(state_time_fixed_lm)

### model with Time-fixed 
state_time_fixed = plm(FR ~ spirits + unemp + income + beertax + jail,data = normData,index = c("state","year"),model = "within",effect = "twoway")
### model without Time-Fixed
stateFix_Model = plm(FR ~ spirits + unemp + income + beertax  + jail ,data = normData,index = c("state","year"),model = "within")
### Test which model is better.
# Testing time-fixed effects. The null is that no time-fixed effects are needed
pFtest(state_time_fixed, stateFix_Model)
###########
### we need time fixed model
###########
summary(state_time_fixed)
summary(stateFix_Model)
state_time_fixed2 = plm(FR ~ spirits + unemp + income + beertax + jail + year+state,data = normData,index = c("state","year"),model = "within",effect = "twoway")
stateFix_Model2 = plm(FR ~ spirits + unemp + income + beertax  + jail+year+state ,data = normData,index = c("state","year"),model = "within")
summary(state_time_fixed2)
summary(stateFix_Model2)

###########
### At this step, we need to test weather we need to use random model or fixed model.
###########

randomModel1 = plm(FR ~ spirits + unemp + income + beertax  + jail ,data = normData,index = c("state","year"),model = "random",effect = "twoway")
randomModel2 = plm(FR ~ spirits + unemp + income + beertax  + jail ,data = normData,index = c("state","year"),model = "random")
phtest(state_time_fixed, randomModel1)
phtest(state_time_fixed, randomModel2)
###########
### ### Fix model is better.
###########


###########
### At this step, we need to test weather we need to use ols model or fixed model.
###########

olsModel = lm(FR ~ spirits + unemp + income + beertax  + jail ,data = normData)
# Testing for fixed effects, null: OLS better than fixed
pFtest(state_time_fixed, olsModel)

###########
### So, we need use state and time fixed model
###########

###############
### The problem of cross-sectional dependence arises 
### if the n individuals in our sample are no longer independently drawn observations but affect each other鈥檚 outcomes. For example, 
### this can result from the fact that we look at a set of neighboring countries, which are usually highly interconnected.
#############
###########
### Cross-sectional dependence testing
###########
pcdtest(state_time_fixed, test = c("cd"))
###########
### we conclude that there is NO cross-sectional dependence
###########


###########
### Serial correlation tests apply to macro panels with long time series. Not a problem in micro panels (with very few years).
###########
pbgtest(state_time_fixed)
###########
### There are only 7 years in this micro panels. So, we do not need to do serial correlation test.
### serial correlation in idiosyncratic errors


### Unit root test
library("aTSA")
adf.test(normData$FR)
### It dose not have unit root, it is stationary




### Model dieognosic
################### 
### Normality test
###################
library("nortest")
lillie.test(residuals(state_time_fixed))
#### It is normal because p value is 0.09144


###################
### multicolinearlity 
###################
modelData = data.frame(normData$unemp,normData$spirits,normData$income,normData$beertax)
solve(cor(modelData,modelData))
#### The VIF is not bigger than 10, so, there is a less multicolinearilty between those variables.


###################
### same variance test
###################
fittedValues = fitted.values(state_time_fixed)
residualsS = residuals(state_time_fixed)
plot(x=as.vector(fittedValues),y = as.vector(residualsS))
### From the plot, we can see the variances are not same at all.

###########
### Heteroskedasticity testing,H0) The null hypothesis for the Breusch-Pagan test is homoskedasticity
###########
bptest(FR~ spirits + unemp + income + beertax  + year + state + jail - 1, data = normData, studentize=F)
###########
### Because p-value < 0.05, we detect hetersokedasticity
### If hetersokedasticity is detected we need to use a robust covariance matrix (Sandwich estimator) to account for it
########### arellano" - both heteroskedasticity and serial correlation. Recommended for fixed effects.
```
```{r echo=FALSE}
coeftest(state_time_fixed)
coeftest(state_time_fixed, vcovHC(state_time_fixed, method = "arellano"))
```

## 3.1 Descriptive Analysis

## 3.2 Main Results

## 3.3 Model Diagnostics and Sensitivity Analysis

### 3.3.1 Diagnostics for Mixed Effect Models

### 3.3.2 Sensitivity Analysis

### 3.3.3 Possibility of Making Causal Statements

```{r message=FALSE, echo=FALSE, include=FALSE}
library(MatchIt)
library(dplyr)
library(ggplot2)
normData %>%
  mutate(test = (FR - mean(FR)) / sd(FR)) %>% #this is how the math score is standardized
  group_by(jail) %>%
  summarise(FRate = mean(test))

fata_cov <- c('spirits', 'unemp', 'income', 'beertax')
normData %>%
  group_by(jail) %>%
  select(one_of(fata_cov)) %>%
  summarise_all(funs(mean(., na.rm = T)))

lapply(fata_cov, function(v) {
  t.test(normData[, v] ~ normData[, 'jail'])
})

fata_cov <- c('unemp', 'income')

m_ps <- glm(jail ~  unemp + income,
            family = binomial(), data = normData)
summary(m_ps)
prs_df <- data.frame(pr_score = predict(m_ps, type = "response"),
                     jail = m_ps$model$jail)
head(prs_df)

labs <- paste("Actual school type attended:", c("Yes", "No"))
prs_df %>%
  mutate(jail = ifelse(jail == "yes", labs[1], labs[2])) %>%
  ggplot(aes(x = pr_score)) +
  geom_histogram(color = "white") +
  facet_wrap(~jail) +
  xlab("Probability of going to Catholic school") +
  theme_bw()

normData2 <- normData %>%
  mutate(jail = ifelse(jail == "yes", 1, 0))

fata_nomiss <- normData2 %>%  # MatchIt does not allow missing values
  select(FR, jail, one_of(fata_cov)) %>%
  na.omit()

mod_match <- matchit(jail ~ unemp + income, method = "nearest", data = fata_nomiss)

dta_m <- match.data(mod_match)
dim(dta_m)

lapply(fata_cov, function(v) {
  t.test(dta_m[, v] ~ dta_m$jail)
})

with(dta_m, t.test(FR ~ jail))

```

To make causal statement about whether having a mandatory jail sentence is associated with reduced traffic fatalities, we use propensity score methods to check the causality of having a mandatory jail sentence. The propensity for panel data requires following assumptions:

* The Stable Unit Treatment Value Assumption: This requires that the outcome of one subject is unaffected by the particular assignment of all other subjects. In our project, fatal rate for each state is independent with others. The relationship between all variables and youth border crossing can be roughly ignored as mentioned before. Besides, the law legislation in each state is independent with other states. Therefore, the fata rate of one state to jail is independent with the fatal rate of other state.
* The numbering of units is done at random, so that the index $\small i$ contains no information. In this project, there is no specific criteria for determining the order of observations for all states. The observed information is mostly involved in other observed variables, for example the spirits consumption, beertax and other variables.
* The treatment is binary: In our project, the treatment jail only has two levels (yes and no).
* The inclusion of all significant covariates. When we use propensity score methods, we need to include all covariates in the final model that are related to both the treatment assignment and potential outcomes. In our project, the final model contains four covariate(spirits, unemployment, income and beertax). Only unemployment and income are significant to both fatal rate and jail in our model. Therefore, we choose only unemployment and income as our covariates in propensity score methods.
* Positivity Assumption: all subjects in the analysis have some probability of receiving the treatment. In our project, we can compare the distribution of propensity scores after executing a matching alogrithm in the group receiving mandatory jail sentence to the distribution of scores in the control group. These distributions shown in Figure 3.3.3.1 are similar. Therefore, it is appropriate to use propensity score method.

```{r echo=FALSE}
m_ps2 <- glm(jail ~  unemp + income,
            family = binomial(), data = dta_m)
prs_df2 <- data.frame(pr_score2 = predict(m_ps2, type = "response"),
                     jail = m_ps2$model$jail)
labs <- paste("Mandatory Jail Sentence:", c("Yes", "No"))
prs_df2 %>%
  mutate(jail = ifelse(jail == "1", labs[1], labs[2])) %>%
  ggplot(aes(x = pr_score2)) +
  geom_histogram(color = "white") +
  facet_wrap(~jail) +
  xlab("Probability distribution of Mandatory Jail Sentence after executing a matching alogrithm") +
  theme_bw()
```
Figure 3.3.3.1 The distribution of propensity scores after executing a matching alogrithm in the group receiving mandatory jail sentence and control group.

Based on the previous analysis, we can make causal statement about whether having a mandatory jail sentence is associated with reduced traffic fatalities. The result given in Table 3.3.3.1 shows that the mandatory jail sentence can cause the increase in fatal rate.
```{r echo=FALSE}
with(normData2, t.test(FR ~ jail))
```
Table 3.3.3.1 The result of t-test for true difference of  fatal rate means in jail sentence group and non jail sentence group is not equal to 0.

```{r message=FALSE, echo=FALSE, include=FALSE}
library(dagitty)
library(ggdag)
dag = dagitty("dag{Jail -> FatalRate; Spirits->FatalRate; Income->FatalRate; Unemployment->FatalRate; Beertax -> FatalRate; }")
ggdag(dag)
```

# 4. Conclusion and Discussion

Based on the previous analysis, following conclusion can be drawn: at significance level $\small \alpha=0.1$, four variables (spirit consumption, unemployment, income and beertax) in our model are all significant to fatal rate. In particular,
* Given other variables fixed, the fatal rate will increase if the spirit consumption increases.
* Given other variables fixed, the fatal rate will decrease if the unemployment increases.
* Given other variables fixed, the fatal rate will increase if the income increases.
* Given other variables fixed, the fatal rate will decrease if the beertax increases.

Times-varying factors still need to be accounted for. Some researchers (e.g. Saffer and Grossman, 1987b: Chaloupka et al., 1993) question the use of FE models because of collinearity between the alcohol variables and other regressors. Multicollinearity increases the standard errors of the coefficients but does not cause bias, in contrast to methods that fail to purge the cross-state heterogeneity. 



\newpage

# 5. Appendix

## 5.1 Session Information

```{r}
print(sessionInfo(), local = FALSE)
```

## 5.2 Reference
[1.] NBER WORKING PAPERS SERIES ALCOHOL CONTROL POLICIES AND MOTOR VEHICLE FATALITIES, Frank J. Chaloupka Henry Saffer Michael Grossman, NATIONAL BUREAU OF ECONOMIC RESEARCH, National Institute on Alcohol Abuse and Alcoholism, Alcohol, Drug Abuse, and Mental Health Administration, Working Paper No.3831, September 1997.
[2.] Alcohol Policies and Highway Vehicle Fatalities, Christopher J. Ruhm. (1996). Alcohol Policies and Highway Vehicle Fatalities. Journal of Health
Economics 15(4): 435-454.

## 5.3 Resources

[1.] https://rstudio-pubs-static.s3.amazonaws.com/372492_3e05f38dd3f248e89cdedd317d603b9a.html#43_random_effects_model. (Getting Started in Fixed/Random Effects Models using R)
[2.] https://sejdemyr.github.io/r-tutorials/statistics/tutorial8.html#estimating-treatment-effects. (R Tutorial 8: Propensity Score Matching)
[3.] https://www.schmidheiny.name/teaching/panel2up.pdf (Short Guides to Microeconometrics, Panel Data: Fixed and Random Effects)

## 5.4 Github information


